---
title: "Measure How Well People Perform Weight Lifting Exercises"
author: "Natalie Phillips"
date: "29 August 2016"
output: 
  html_document: 
    keep_md: yes
---

```{r setup1, include=FALSE}
#knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```

```{r setup, cache = F, echo = F, message = F, warning = F, tidy = F}
library(knitr)
library(caret)
# make this an external chunk that can be included in any file
options(width = 100)
opts_chunk$set(message = F, error = F, warning = F, comment = NA, fig.align = 'center', dpi = 100, cache=TRUE,tidy = F, cache.path = '.cache/', fig.path = 'fig/')

options(xtable.type = 'html')
knit_hooks$set(inline = function(x) {
  if(is.numeric(x)) {
    round(x, getOption('digits'))
  } else {
    paste(as.character(x), collapse = ', ')
  }
})
knit_hooks$set(plot = knitr:::hook_plot_html)
```

## Synopsis

It is now common for people to measure how much of an activity they are doing.
It is less common for people to measure how well are completing an activity.
It is possible to accruately predict whether barbell lifts have been performed 
correctly as the analysis below demostrates. This ability to predict how a person
is moving has great implications for automated coaching and feedback for people
both in and out of home and the gym.

A group of volunteers were asked to lift dumbells in an exercise called *Unilateral Dumbbell Biceps Curl*. They were asked to lift the weights using the correct technique or
one of four common errors.

Label for lift     |   Lift technique
-----------      |   --------------
class A         |   correct lift
class B         |   throwing elbows to the front
class C         |   lifting only half way
class D         |   lowering only half way
class E         |   throwing hips to the front.

The excercise was measured using sensors called accelerometers on various parts of the body as well 
as the dumbells. Sensors were placed on:

* arm
* forearm
* belt
* dumbell.

## Loading and processing data

First the data were first downloaded. A check is performed to see if the data were already there so the download only occurs once.

```{r download, echo = FALSE}
#Create a data directory if one isn't already there
if (!file.exists("data")){
    dir.create("data")
}

#Location where files can be downloaded from
trainUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

#Have files already been downloaded? If not then download.
if (!file.exists(".\\data\\pml-training.csv")){
    download.file(trainUrl, destfile = ".\\data\\pml-training.csv", method = "curl")
}

if (!file.exists(".\\data\\pml-testing.csv")){
    download.file(testUrl, ".\\data\\pml-testing.csv", method = "curl")
}

```

The data were presplit into a testing set and a training set where were then loaded into R. During the load both *NA* and *#DIV/0!* were read as *NA* strings.

```{r load, cache=TRUE}
train <- read.csv(".\\data\\pml-training.csv",
                  na.strings = c("NA", "#DIV/0!")
                  )
test <- read.csv(".\\data\\pml-testing.csv",
                 na.strings = c("NA", "#DIV/0!")
                    )
```

The train set has `r dim(train)[2]` variables and `r dim(train)[1]` observations. The test set has the same number of variables less the *classe* (results) column and `r dim(test)[1]` observations.

Cleaning of the data was performed in three ways:

* where most of the measurements were $NA$s the variable was removed
* names dates and indexes are not relevant to the prediction so were removed
* one outlier was removed.

There was one outlier value, well outside the range of the rest of the values,  which could have been caused by a miss read on the sensors or perhaps dropped equipment.



Not all of the variables are useful for our model. It turns out some variables
contained mainly NA values which were removed below.

```{r clean, cache= TRUE}
library(plyr)
library(dplyr)
# Remove rows containing mainly NAs
nmissing <- function(x) {
    sum(is.na(x))   # Calculate the number of NAs
}

NA_Col <- which(colwise(nmissing)(train) > 19000)
train2 <- train[, -NA_Col] # Remove columns with NAs

# Remove names and dates
train2 <- train2[, -(1:5)]

# Remove outlier
summary(train2$gyros_dumbbell_x)
locat <- which(train2$gyros_dumbbell_x < -10)
train2 <- train2[-locat, ]
```

The cleaned training set has `r dim(train2)[2]` variables and `r dim(train2)[1]` observations. The outlier was skewing the data and removing it has allowed data for some of the variables to be less skewed. For example take the variable *gyros_dumbbell_x*.You can see the change that occurs when removing the outlier:


```{r plot1, cache= TRUE, echo = FALSE}
par(mfrow=c(1, 2))
with(train, plot(gyros_dumbbell_x, col=classe,
                 main = "All observations"))
                #legend("bottomright", col=col, legend=train$classe)
with(train2, plot(gyros_dumbbell_x, col=classe,
                  main = "Outlier removed"))

```

## Random Forest model

I chose Random Forests methods to model the type of movement performed by the
subject due to its accuracy and the fact that the data do not appear normal. No other preprocessing in the form of scaling or reshaping was performed as the Random Forest method does not require it. 

Error was calculated using k-fold Cross Validation with 10 foldes. Cross Validation should provide a reasonable out of sample estimate.

Unfortunately the computer I was using for machine learning could not build a model with all of training observations provided. I used around 30% observation to make the calculations more manageable. The data left out of the taining model 
was used to validate the model once it was built.

```{r predict, cache=TRUE}
library(caret)
library(rpart)

# Make the size more manageable and speed up computations
set.seed(1375)
trainSmall <- createDataPartition(y = train2$classe, p = 0.3, list = FALSE)
train3 <- train2[trainSmall, ]

# Train the Random Forest model with 10 fold Cross Validations 
modelRF <- train(classe ~ .,
                  data = train3,
                  method = "rf",
                  trControl = trainControl(method = "cv", number = 10),
                  prox = TRUE)
```

The model has over an 98% accuracy as seen in the confusion matrix below:
```{r results}
confusionMatrix(modelRF)
```

This model was applied to the 20 observation test set and independently verified to be 100% successfull.

## Validation

Training data, not used to build the model, was used to test the prediction model. We don't need to perform any preprocessing as no transformations were performed. Also the prediction model will only references those columns named in the model.

```{r prediction, cache=TRUE}
# Predicting using the remaining training data
test2 <- train2[-trainSmall, ]
pred <- predict(modelRF, test2)
confusionMatrix(pred, test2$classe)
```

The Confusion Matrix shows the predicted value down the left hand side and the 
correct observed values across the top. See that most of the predicted values
agreed with the observered values. The out of the bag Accuracy is over 99%. 

## Variables with the most impact on the model

The most important variables according to the model were

```{r}
varImp(modelRF)
```

The four variables with the most impact on the model are shown below. The Class of movement is shown in colour:

* black - class A
* red - class B
* green - class C
* dark blue - class D
* light blue - class E

```{r plot2, cache= TRUE, echo = FALSE}
par(mfrow=c(2, 2))
with(train, plot(num_window, col=classe,
                 main = "num_window"))
                #legend("bottomright", col=col, legend=train$classe)
with(train, plot(roll_belt, col=classe,
                  main = "roll_belt"))
with(train, plot(pitch_forearm, col=classe,
                 main = "pitch_forearm"))
                #legend("bottomright", col=col, legend=train$classe)
with(train, plot(yaw_belt, col=classe,
                  main = "yaw_belt"))
```

## Conclusions
With over 99% accuracy this model shows just how accurately technique in the gym can be captured. This will likely open up many new coaching applications and gadgets in the fitness industry and beyond.



## Citation

I gratefully cite this paper and data collection work which made this analysis possible.

Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. **Qualitative Activity Recognition of Weight Lifting Exercises**. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.

## Further work

* It appears one of the most important measures when predicting how well an excercise
is performed is **num_window**. This value may not be known outside of
an experimental environment. Perhaps next time this variable along with **new_window**
should be removed.

* A more powerful machine would enable the Random Forest model to be built using all of the observations which may improve the accuracy some what.
